{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Project \n",
    "\n",
    "Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral. It’s also known as opinion mining, deriving the opinion or attitude of a speaker.A common use case for this technology is to discover how people feel about a particular topic.\n",
    "\n",
    "<img src=\"./Sentiment_Analysis_Image.jpg\" alt=\"Image of Sentiment Analysis\" style=\"height:600px; width:400\"/>\n",
    "\n",
    "Sentiment Analysis is a widlely adopted practise allover the world. In fact, sentiment analysis is useful in several areas whether in politics where we can analyse attitudes to goverment agencies or in Business analytics where we can track customers reviews. Sentiment Analysis is also used in psychology, sociology, law making...etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Context\n",
    "This project is about peoples' reviews concerning a famous Tunisian football player Youusef Msakni. \n",
    "Youssef Msakni (born 28 October 1990) is a Tunisian professional footballer who plays for Qatar Stars League club Al-Duhail.\n",
    "He was formed at Stade Tunisien, he evolves in July 2008 in the club of the ES Tunis.\n",
    "<img src=\"./youssef_msakni.jpg\" alt=\"Youssef Mskani\" style=\"width:400px;height:600px\"/>\n",
    "<b>Palmares :<b>\n",
    "<ul>\n",
    " <li><strong>2011 : </strong>Championnat d’Afrique des nations.</li>\n",
    " <li><strong>2009 : </strong>CAF Champions League.</li>\n",
    " <li><strong>2009 : </strong>North African Cup Winners' Cup.</li>\n",
    " <li><strong>2009, 2010, 2011, 2012 : </strong>Champion of Tunisia with Esperance of Tunis.</li>\n",
    " <li><strong>2011 : </strong>Tunisian Cup with Esperance of Tunis.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data used in this project is about people's reviews concerning Youssef Mskani dating back to year 2016 with the newest data being as late as 16 Mai 2017. This data was extracted thanks to Youtube API and Facebook API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import entire libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#library for plotting stuff\n",
    "import matplotlib.pyplot as plt\n",
    "#so that plots appear in the same browser window\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "## Import specific items only from the sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from a file\n",
    "data = pd.read_csv('./youssef_msakni.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>sentiment_categorie</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa77a nemes mnawer frr</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-10-11T01:14:34+0000</td>\n",
       "      <td>https://www.facebook.com/YoussefMsekni.fans/ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pff</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2011-12-26T09:39:58+0000</td>\n",
       "      <td>https://www.facebook.com/Youssef.28.Msakni/pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le meilleur joueur de la tunisie cest msakni</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-05-18T18:33:41.000Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=KV2WpPMM90E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yassir tfaded</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2017-11-13T18:20:15+0000</td>\n",
       "      <td>https://www.facebook.com/YoussefMsekni.fans/ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M3allem</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-12-22T08:43:10+0000</td>\n",
       "      <td>https://www.facebook.com/Youssef.7.Msekni/phot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   comment_text sentiment_categorie  \\\n",
       "0                        Sa77a nemes mnawer frr             positif   \n",
       "1                                           pff             negatif   \n",
       "2  le meilleur joueur de la tunisie cest msakni             positif   \n",
       "3                                 Yassir tfaded             negatif   \n",
       "4                                       M3allem             positif   \n",
       "\n",
       "                       date                                                url  \n",
       "0  2017-10-11T01:14:34+0000  https://www.facebook.com/YoussefMsekni.fans/ph...  \n",
       "1  2011-12-26T09:39:58+0000  https://www.facebook.com/Youssef.28.Msakni/pho...  \n",
       "2  2017-05-18T18:33:41.000Z        https://www.youtube.com/watch?v=KV2WpPMM90E  \n",
       "3  2017-11-13T18:20:15+0000  https://www.facebook.com/YoussefMsekni.fans/ph...  \n",
       "4  2017-12-22T08:43:10+0000  https://www.facebook.com/Youssef.7.Msekni/phot...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaing the first 5 comments \n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and understand the data matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new binary sentiment category variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new binary ratings variable:\n",
    "#   = 1 if rating == 'positif'\n",
    "#   = 0 if rating == 'negatif'\n",
    "z = np.where(data['sentiment_categorie'] =='positif', 1,0)\n",
    "data['sentiment_categorie_Binary'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment_categorie_Binary\n",
       "0     97\n",
       "1    312\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gR = data.groupby('sentiment_categorie_Binary').size()\n",
    "print(type(gR))\n",
    "gR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 2 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npM79P7XQ3ovV2BOdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb969ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(gR.index, gR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>sentiment_categorie</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment_categorie_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa77a nemes mnawer frr</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-10-11T01:14:34+0000</td>\n",
       "      <td>https://www.facebook.com/YoussefMsekni.fans/ph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>le meilleur joueur de la tunisie cest msakni</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-05-18T18:33:41.000Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=KV2WpPMM90E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M3allem</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-12-22T08:43:10+0000</td>\n",
       "      <td>https://www.facebook.com/Youssef.7.Msekni/phot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aller Yuossef</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-07-05T02:20:51.000Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=i2WUo3tzM6Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mnawer ya msakni</td>\n",
       "      <td>positif</td>\n",
       "      <td>2017-10-10T17:22:00+0000</td>\n",
       "      <td>https://www.facebook.com/YoussefMsekni.fans/ph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   comment_text sentiment_categorie  \\\n",
       "0                        Sa77a nemes mnawer frr             positif   \n",
       "2  le meilleur joueur de la tunisie cest msakni             positif   \n",
       "4                                       M3allem             positif   \n",
       "5                                 aller Yuossef             positif   \n",
       "6                              Mnawer ya msakni             positif   \n",
       "\n",
       "                       date  \\\n",
       "0  2017-10-11T01:14:34+0000   \n",
       "2  2017-05-18T18:33:41.000Z   \n",
       "4  2017-12-22T08:43:10+0000   \n",
       "5  2017-07-05T02:20:51.000Z   \n",
       "6  2017-10-10T17:22:00+0000   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.facebook.com/YoussefMsekni.fans/ph...   \n",
       "2        https://www.youtube.com/watch?v=KV2WpPMM90E   \n",
       "4  https://www.facebook.com/Youssef.7.Msekni/phot...   \n",
       "5        https://www.youtube.com/watch?v=i2WUo3tzM6Y   \n",
       "6  https://www.facebook.com/YoussefMsekni.fans/ph...   \n",
       "\n",
       "   sentiment_categorie_Binary  \n",
       "0                           1  \n",
       "2                           1  \n",
       "4                           1  \n",
       "5                           1  \n",
       "6                           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some positive examples\n",
    "data[data['sentiment_categorie_Binary'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>sentiment_categorie</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment_categorie_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pff</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2011-12-26T09:39:58+0000</td>\n",
       "      <td>https://www.facebook.com/Youssef.28.Msakni/pho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yassir tfaded</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2017-11-13T18:20:15+0000</td>\n",
       "      <td>https://www.facebook.com/YoussefMsekni.fans/ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Far5 cha9nous</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2017-11-19T21:27:25+0000</td>\n",
       "      <td>https://www.facebook.com/Youssef.7.Msekni/phot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hetha el cha5ss min anwe3 el 7atharet el nadra</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2017-09-15T14:05:55.000Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=YXGdt6ppv5c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>moch rajel w 9oaalit el rojlla</td>\n",
       "      <td>negatif</td>\n",
       "      <td>2017-07-25T19:43:26.000Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=YXGdt6ppv5c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_text sentiment_categorie  \\\n",
       "1                                              pff             negatif   \n",
       "3                                    Yassir tfaded             negatif   \n",
       "11                                   Far5 cha9nous             negatif   \n",
       "14  hetha el cha5ss min anwe3 el 7atharet el nadra             negatif   \n",
       "18                  moch rajel w 9oaalit el rojlla             negatif   \n",
       "\n",
       "                        date  \\\n",
       "1   2011-12-26T09:39:58+0000   \n",
       "3   2017-11-13T18:20:15+0000   \n",
       "11  2017-11-19T21:27:25+0000   \n",
       "14  2017-09-15T14:05:55.000Z   \n",
       "18  2017-07-25T19:43:26.000Z   \n",
       "\n",
       "                                                  url  \\\n",
       "1   https://www.facebook.com/Youssef.28.Msakni/pho...   \n",
       "3   https://www.facebook.com/YoussefMsekni.fans/ph...   \n",
       "11  https://www.facebook.com/Youssef.7.Msekni/phot...   \n",
       "14        https://www.youtube.com/watch?v=YXGdt6ppv5c   \n",
       "18        https://www.youtube.com/watch?v=YXGdt6ppv5c   \n",
       "\n",
       "    sentiment_categorie_Binary  \n",
       "1                            0  \n",
       "3                            0  \n",
       "11                           0  \n",
       "14                           0  \n",
       "18                           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some negative examples\n",
    "data[data['sentiment_categorie_Binary'] == 0].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306L,)\n",
      "(103L,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['comment_text'], \n",
    "                                                    data['sentiment_categorie_Binary'], \n",
    "                                                    random_state=591)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265    J'adorerais voir cette été msakni a l'om ou o ...\n",
       "279                                   hĥhhhhh ya youssif\n",
       "74                                      Rabi yhanik Nems\n",
       "96                Faraahna ya youssef fi l mondiale !! ❤\n",
       "322                               Sadkouni hkéytou férga\n",
       "346                       Bon année ya nems ya 4ali❤❤❤❤❤\n",
       "240                                               Mahlek\n",
       "89                                  best so proud of him\n",
       "53                                       Nîmes ya m3alem\n",
       "248                                     yezi mel tbourib\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some train examples\n",
    "X_train.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis based on BOW model with word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize documents & build vocabulary set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "#  i.e. learn the vocabulary (distinct words) of the input corpus\n",
    "vect.fit(X_train)\n",
    "print len(vect.get_feature_names())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct document-term matrix\n",
    "- This matrix contains the *feature vectors* of a given set of raw documents.\n",
    "- For the simple BOW model, feature vector = number of word occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 765)\n",
      "(103, 765)\n"
     ]
    }
   ],
   "source": [
    "# the document-term matrix for the training corpus\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "print(X_train_vectorized.shape)\n",
    "# the document-term matrix for the testing corpus\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "print(X_test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods and features\n",
    "\n",
    "Existing approaches to sentiment analysis can be grouped into three main categories: \n",
    "<ul>\n",
    "<li>knowledge-based techniques</li>\n",
    "<li>statistical methods</li>\n",
    "<li>hybrid approaches</li>\n",
    "</ul>\n",
    "\n",
    "Knowledge-based techniques classify text by affect categories based on the presence of unambiguous affect words such as happy, sad, afraid, and bored.\n",
    "Some knowledge bases not only list obvious affect words, but also assign arbitrary words a probable \"affinity\" to particular emotions.\n",
    "\n",
    "Statistical methods leverage on elements from machine learning such as latent semantic analysis, support vector machines, \"bag of words\" and Semantic Orientation. More sophisticated methods try to detect the holder of a sentiment (i.e., the person who maintains that affective state) and the target (i.e., the entity about which the affect is felt). To mine the opinion in context and get the feature about which the speaker has opined, the grammatical relationships of words are used. Grammatical dependency relations are obtained by deep parsing of the text.\n",
    "\n",
    "Hybrid approaches leverage on both machine learning and elements from knowledge representation such as ontologies and semantic networks in order to detect semantics that are expressed in a subtle manner.\n",
    "\n",
    "In Our case we have choose <strong>Statistical methods</strong> such as <strong>Logistic Regression</strong> and <strong>Naive Bayes</strong>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classification model using Logistic Regression\n",
    "We are going to  to build a classification model using the feature vectors of the training documents (which are stored in the variable ``X_train_vectorized``) and their corresponding true sentiment categories (which are stored in the variable ``y_train``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using LR method\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the classification model\n",
    "We'll use the obtained LR model to predict sentiment categories (classes) of test documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(103L,)\n"
     ]
    }
   ],
   "source": [
    "# Use this model to predict the sentiment category of test documents\n",
    "LR_predictions = LR_model.predict(X_test_vectorized)\n",
    "print(type(LR_predictions))\n",
    "print(LR_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1]\n",
      "[0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(LR_predictions[:30])\n",
    "print(np.array(y_test[:30]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance of classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84466019417475724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classif_rate = accuracy_score(y_test, LR_predictions)\n",
    "LR_classif_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Interpretation of model's coefficients (parameters)\n",
    "Which vocabulary words are most important in our classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first get LR model's coefficient (there is one coefficient per vocabulary word)\n",
    "coefs = LR_model.coef_[0]\n",
    "\n",
    "# Sort these coefficient values in ascending order\n",
    "sorted_coef_index = coefs.argsort()  #sort by actual value\n",
    "sorted_coef_index_2 = abs(coefs).argsort()  #sort by absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs of LR model:\n",
      "\n",
      " Coefficient values:\n",
      "[-1.2643061  -1.2500539  -1.03622996 -0.9196204  -0.85596242 -0.84602087\n",
      " -0.81291393 -0.78391104 -0.77903442 -0.77903442]\n",
      "\n",
      " Feature names:\n",
      "[u'rajel' u'malla' u'tfouuuhhh' u'jabri' u'mel' u'yezi' u'el' u'mrith'\n",
      " u'tfaded' u'yassir']\n",
      "\n",
      "Largest Coefs of LR model:\n",
      "\n",
      " Coefficient values: \n",
      "[ 1.20238208  1.13517087  0.95859918  0.8221765   0.70004327  0.69264705\n",
      "  0.65904479  0.64994938  0.6242271   0.58173524]\n",
      " Feature names: \n",
      "[u'rabi' u'm3alem' u'nems' u'bravo' u'm3allem' u'msekni' u'mnawer' u'the'\n",
      " u'youssef' u'saha']\n",
      "Smallest abs(Coefs):\n",
      "\n",
      " Coefficient values:\n",
      "[ 0.00339147  0.00339147  0.00339147  0.01053898  0.01053898  0.01053898\n",
      "  0.01053898  0.01053898  0.01053898  0.01053898]\n",
      "\n",
      " Feature names:\n",
      "[u'europa' u'africa' u'america' u'wled' u'3endha' u'kifkom' u'tefta5er'\n",
      " u'nousourna' u'rfe3toulna' u'rousna']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the 10 smallest and 10 largest coefficients\n",
    "\n",
    "#feature_names = vect.get_feature_names()\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "print('Smallest Coefs of LR model:\\n')\n",
    "print(' Coefficient values:\\n{}\\n'.format(coefs[sorted_coef_index[:10]]))\n",
    "print(' Feature names:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "\n",
    "print('Largest Coefs of LR model:\\n')\n",
    "print(' Coefficient values: \\n{}'.format(coefs[sorted_coef_index[:-11:-1]]))\n",
    "print(' Feature names: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "\n",
    "print('Smallest abs(Coefs):\\n')\n",
    "print(' Coefficient values:\\n{}\\n'.format(coefs[sorted_coef_index_2[:10]]))\n",
    "print(' Feature names:\\n{}\\n'.format(feature_names[sorted_coef_index_2[:10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classification model using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build Naive Bayes classification model\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this model to predict sentiment of test documents\n",
    "\n",
    "NB_predictions = NB_model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate performance of classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87378640776699024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate model's classification rate on the test corpus\n",
    "\n",
    "NB_classif_rate = accuracy_score(y_test, NB_predictions)\n",
    "NB_classif_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluation\n",
    "The accuracy of a sentiment analysis system is, in principle, how well it agrees with human judgments. This is usually measured by variant measures based on precision and recall over the two target categories of negative and positive texts.\n",
    "\n",
    "Thus, a program which achieves <strong>70%</strong> accuracy in classifying sentiment is doing nearly as well as humans, even though such accuracy may not sound impressive. If a program were \"right\" <strong>100%</strong> of the time, humans would still disagree with it about <strong>20%</strong> of the time, since they disagree that much about any answer.\n",
    "\n",
    "In our case the<strong> accurancy</strong >of our classification Model build with <strong>Linear regression</strong> is\n",
    "<div style=\"color: red;\">0.84</div> however it is <div style=\"color: red;\">0.87</div> for our classification Model build with<strong> Naive Bayes</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
